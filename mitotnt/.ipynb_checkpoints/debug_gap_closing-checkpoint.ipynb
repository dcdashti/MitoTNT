{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c667ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "from tqdm.notebook import trange\n",
    "from scipy.optimize import linear_sum_assignment as lap_solver\n",
    "from fastdist import fastdist\n",
    "from network_tracking import local_graph_comparison_score, list_to_str\n",
    "\n",
    "work_dir = 'D:/Python Scripts/Mito/MitoTNT/test_data/'\n",
    "data_dir = work_dir+'mitograph/'\n",
    "input_dir = work_dir+'tracking_input/'\n",
    "if not os.path.isdir(input_dir):\n",
    "    os.mkdir(input_dir)\n",
    "\n",
    "start_frame = 0\n",
    "end_frame = len([frame for frame in os.listdir(data_dir) if 'FRAME' in frame])\n",
    "\n",
    "track_dir = work_dir+'tracking_ouput/'\n",
    "if not os.path.isdir(track_dir):\n",
    "    os.mkdir(track_dir)\n",
    "\n",
    "tracking_interval = 1\n",
    "graph_matching_depth = 2\n",
    "dist_exponent, top_exponent = 1, 1\n",
    "\n",
    "min_track_size = 4\n",
    "max_gap_size = 2\n",
    "memory_efficient_gap_closing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc600ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap closing in progress ...\n",
      "Data loading ...\n"
     ]
    }
   ],
   "source": [
    "## reload all tracks\n",
    "all_tracks = np.load(track_dir+'/all_tracks.npy', allow_pickle=True)\n",
    "\n",
    "# filter out very short tracks\n",
    "very_short_tracks = []\n",
    "for i in range(len(all_tracks)):\n",
    "    if len(all_tracks[i][0]) < min_track_size:\n",
    "        very_short_tracks.append(i)\n",
    "\n",
    "all_tracks = np.delete(all_tracks, very_short_tracks, axis=0)\n",
    "all_tracks = sorted(all_tracks, key=lambda track : track[0][0]) # sort by start frame\n",
    "num_tracks = len(all_tracks)\n",
    "\n",
    "print('Gap closing in progress ...')\n",
    "\n",
    "# get track disps\n",
    "all_track_disps = []\n",
    "for t in all_tracks:\n",
    "    track_coords = t[4] # use index for the coordinates\n",
    "    all_track_disps.append([np.linalg.norm(track_coords[t+1]-track_coords[t]) for t in range(len(track_coords)-1)])\n",
    "\n",
    "# store intermediate values\n",
    "print('Data loading ...')\n",
    "inputs = np.load(input_dir+'tracking_inputs.npz', allow_pickle=True)\n",
    "full_graph_all_frames = inputs['full_graphs']\n",
    "classic_graph_per_node_all_frames = inputs['classic_graphs_per_node']\n",
    "segment_node_all_frames = inputs['segment_nodes']\n",
    "\n",
    "all_track_assignments = {}\n",
    "partition_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc40a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition index: 0 4260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c32d94fa574440a970aa988af14993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "276 MB \n",
      "\n",
      "Partition index: 3550 7810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5428750824b34468be40cbc05a2ea1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "276 MB \n",
      "\n",
      "Partition index: 7100 11360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5540e30c6874a9d9bbe40d66c651df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "276 MB \n",
      "\n",
      "Partition index: 10650 13225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cb14a5dbe040abb5f11c80bbd9da92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "276 MB \n",
      "\n"
     ]
    }
   ],
   "source": [
    "while partition_start < num_tracks:\n",
    "    num_frame = end_frame-start_frame\n",
    "\n",
    "    if not memory_efficient_gap_closing:\n",
    "        partition_size = num_tracks\n",
    "        overlap_size = 0\n",
    "    else:\n",
    "        partition_size = int(num_tracks / num_frame) * 30\n",
    "        overlap_size =  int(num_tracks / num_frame) * 5\n",
    "\n",
    "    partition_end = partition_start + partition_size\n",
    "    if partition_end > num_tracks:\n",
    "        partition_end = num_tracks\n",
    "    print('Partition index:', partition_start, partition_end)\n",
    "\n",
    "    track_cost_m_n = np.empty([partition_size, partition_size])\n",
    "    track_cost_m_n[:] = np.nan\n",
    "\n",
    "    for i in trange(partition_start, partition_end):\n",
    "\n",
    "        track_frames_m, track_nodes_m, track_coords_m = all_tracks[i][0], all_tracks[i][1], all_tracks[i][4]\n",
    "        end_frame_m, end_node_m, end_coord_m = track_frames_m[-1], track_nodes_m[-1], track_coords_m[-1]\n",
    "\n",
    "        # load data\n",
    "\n",
    "        classic_graphs_m = classic_graph_per_node_all_frames[end_frame_m]\n",
    "        disps_m = all_track_disps[i]\n",
    "\n",
    "        for j in range(i+1, partition_end): # no need to check index less than i because the start frame is sorted\n",
    "\n",
    "            track_frames_n, track_nodes_n, track_coords_n = all_tracks[j][0], all_tracks[j][1], all_tracks[j][4]\n",
    "            start_frame_n, start_node_n, start_coord_n = track_frames_n[0], track_nodes_n[0], track_coords_n[0]\n",
    "\n",
    "            gap_size = start_frame_n - end_frame_m - 1\n",
    "\n",
    "            # check only those within max gap size\n",
    "            if 1 <= gap_size <= max_gap_size: # if gap == 1 it should have been linked before - so skip it\n",
    "\n",
    "                # load data\n",
    "                classic_graphs_n = classic_graph_per_node_all_frames[start_frame_n]\n",
    "\n",
    "                # compute distance cutoff based on the two tracks\n",
    "                disps_n = all_track_disps[j]\n",
    "                comb_disps = disps_m + disps_n\n",
    "\n",
    "                dist_cutoff = (gap_size + 1) * (3 * np.std(comb_disps)) ** 2\n",
    "\n",
    "                # compute node-to-node distance\n",
    "                dist = end_coord_m - start_coord_n\n",
    "                dist_cost = np.sum(dist**2)\n",
    "\n",
    "                # filter by distance cutoff\n",
    "                if dist_cost > dist_cutoff:\n",
    "                    continue\n",
    "\n",
    "                # compute topology cost\n",
    "                topology_cost = local_graph_comparison_score(graph_matching_depth, end_node_m, start_node_n, classic_graphs_m, classic_graphs_n)\n",
    "\n",
    "                # assign g.c. cost\n",
    "                track_cost_m_n[i-partition_start,j-partition_start] = dist_cost**dist_exponent * topology_cost**top_exponent\n",
    "\n",
    "    # construct termination cost matrix\n",
    "    track_cost_m_m = np.empty([partition_size, partition_size])\n",
    "    track_cost_m_m[:] = np.nan\n",
    "\n",
    "    for i in range(partition_size):\n",
    "        row = track_cost_m_n[i,:]\n",
    "\n",
    "        if np.isnan(row).all():\n",
    "            track_cost_m_m[i,i] = 0 # must be assigned to itself since all other nodes exceed max radius\n",
    "        else:\n",
    "            min_cost = np.nanmin(row)\n",
    "            track_cost_m_m[i,i] = 1.5 * min_cost\n",
    "            # track_cost_m_m[i,i] = np.nanpercentile(row, 90, interpolation='midpoint')\n",
    "\n",
    "    # assemble into one matrix\n",
    "    track_cost_matrix = np.concatenate((track_cost_m_n, track_cost_m_m), axis=1)\n",
    "    track_cost_matrix[np.isnan(track_cost_matrix)] = np.inf\n",
    "\n",
    "    # evaluate memory usage\n",
    "    print('\\n%d MB' % (track_cost_matrix.nbytes / 1024**2), '\\n')\n",
    "\n",
    "    # solve LAP and store linking results\n",
    "    assignment = lap_solver(track_cost_matrix)[1]\n",
    "\n",
    "    linked, terminated, initiated = [], [], []\n",
    "    for i in range(len(assignment)):\n",
    "        if assignment[i] < partition_size:\n",
    "            linked.append([i, assignment[i]]) # first being index for frame t and second for frame t+tracking_interval\n",
    "        else:\n",
    "            terminated.append(i)\n",
    "\n",
    "    for pair in linked:\n",
    "        all_track_assignments[partition_start + pair[0]] = partition_start + pair[1] # offset by start index of the partition\n",
    "\n",
    "    # go to next partition\n",
    "    partition_start = partition_start + partition_size - overlap_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6496a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dictionary to array and overwrite assignment by next partition's assignment for the overlapped region\n",
    "linked_tracks = np.zeros([len(all_track_assignments.keys()), 2], dtype=int)\n",
    "for i, a in enumerate(all_track_assignments.keys()):\n",
    "    linked_tracks[i,0] = a\n",
    "    linked_tracks[i,1] = all_track_assignments[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aeba43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  1458],\n",
       "       [    2,  1529],\n",
       "       [    3,  1483],\n",
       "       ...,\n",
       "       [12416, 13187],\n",
       "       [12419, 13223],\n",
       "       [12420, 13199]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409056d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start combining closed tracks ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949e5cebfdf4447bab0e74847c232e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine tracks for gap closing\n",
    "print('Start combining closed tracks ...')\n",
    "if linked_tracks.shape[0] > 0:\n",
    "    linked_tracks_for_update = linked_tracks.copy() # used to record appended tracks\n",
    "    tracks_of_track = [] # list of linked tracks\n",
    "    all_linked_tracks = [] # record tracks that are closed\n",
    "\n",
    "    # recursive function for finding linked tracks\n",
    "    def find_all_linked_tracks(tracks, track_id):\n",
    "        for i in range(0, len(linked_tracks_for_update)):\n",
    "            if linked_tracks_for_update[i,0] == track_id: # find the first track\n",
    "                tracks.append(linked_tracks_for_update[i,1])\n",
    "                linked_tracks_for_update[i,0] = -1 # note that the track is already appended\n",
    "                find_all_linked_tracks(tracks, linked_tracks_for_update[i,1]) # go to the next track and find linked_tracks track\n",
    "\n",
    "    # for each track find the series of linked tracks\n",
    "    for index in trange(len(linked_tracks)):\n",
    "        track_id = linked_tracks[index,0]\n",
    "        if track_id in linked_tracks_for_update[:,0]:\n",
    "            tracks = [track_id]\n",
    "            find_all_linked_tracks(tracks, track_id)\n",
    "            tracks_of_track.append(tracks)\n",
    "            all_linked_tracks += tracks\n",
    "\n",
    "    # concatenate data for closed tracks\n",
    "    all_closed_tracks = []\n",
    "    for tot in tracks_of_track:\n",
    "        all_closed_tracks.append([sum([all_tracks[t][0] for t in tot], []),\n",
    "                                  sum([all_tracks[t][1] for t in tot], []),\n",
    "                                  sum([all_tracks[t][2] for t in tot], []),\n",
    "                                  sum([all_tracks[t][3] for t in tot], []),\n",
    "                                  sum([all_tracks[t][4] for t in tot], []),\n",
    "                                  sum([all_tracks[t][5] for t in tot], []),\n",
    "                                  sum([all_tracks[t][6] for t in tot], [])])\n",
    "\n",
    "    # add unclosed tracks back\n",
    "    for t in range(num_tracks):\n",
    "        if t not in all_linked_tracks:\n",
    "            all_closed_tracks.append(all_tracks[t].tolist())\n",
    "\n",
    "    # sort tracks\n",
    "    sort_by_length = sorted(all_closed_tracks, key=lambda track : len(track[0]), reverse=True) # first sort by size of track\n",
    "    sort_by_start = sorted(sort_by_length, key=lambda track : track[0][0]) # then sort by start frame\n",
    "    all_closed_tracks = sort_by_start\n",
    "\n",
    "else:\n",
    "    all_closed_tracks = all_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d58d829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18],\n",
       " [3, 3, 4, 1, 7, 10, 15, 11, 15, 13, 6, 5, 4, 1328, 7, 5, 7],\n",
       " [243,\n",
       "  268,\n",
       "  237,\n",
       "  271,\n",
       "  259,\n",
       "  266,\n",
       "  260,\n",
       "  258,\n",
       "  274,\n",
       "  268,\n",
       "  244,\n",
       "  274,\n",
       "  274,\n",
       "  262,\n",
       "  259,\n",
       "  259,\n",
       "  255],\n",
       " [3, 2, 3, 1, 5, 5, 5, 3, 1, 0, 5, 3, 2, 2, 1, 4, 0],\n",
       " [array([158., 125.,  42.]),\n",
       "  array([155., 124.,  42.]),\n",
       "  array([155., 122.,  42.]),\n",
       "  array([157., 121.,  43.]),\n",
       "  array([160., 122.,  42.]),\n",
       "  array([158., 127.,  41.]),\n",
       "  array([158., 128.,  41.]),\n",
       "  array([157., 129.,  41.]),\n",
       "  array([156., 129.,  41.]),\n",
       "  array([152., 129.,  40.]),\n",
       "  array([151., 129.,  42.]),\n",
       "  array([150., 125.,  42.]),\n",
       "  array([150., 123.,  42.]),\n",
       "  array([151., 124.,  42.]),\n",
       "  array([148., 126.,  41.]),\n",
       "  array([146., 127.,  42.]),\n",
       "  array([147., 127.,  41.])],\n",
       " [851.5,\n",
       "  1017.33333,\n",
       "  1406.66667,\n",
       "  923.0,\n",
       "  1921.33333,\n",
       "  2066.66667,\n",
       "  1721.5,\n",
       "  1152.5,\n",
       "  1813.0,\n",
       "  1071.0,\n",
       "  1651.33333,\n",
       "  1592.66667,\n",
       "  1305.5,\n",
       "  1499.66667,\n",
       "  1222.16667,\n",
       "  2050.0,\n",
       "  1371.33333],\n",
       " [1.2906,\n",
       "  1.86897,\n",
       "  2.32766,\n",
       "  2.14363,\n",
       "  3.06528,\n",
       "  2.9701,\n",
       "  2.53723,\n",
       "  2.11394,\n",
       "  3.25929,\n",
       "  1.9536,\n",
       "  2.82771,\n",
       "  2.79533,\n",
       "  2.2234,\n",
       "  3.20607,\n",
       "  2.37771,\n",
       "  2.84842,\n",
       "  3.0903]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = tracks_of_track[0]\n",
    "[sum([all_tracks[t][0] for t in tot], []),\n",
    "                                  sum([all_tracks[t][1] for t in tot], []),\n",
    "                                  sum([all_tracks[t][2] for t in tot], []),\n",
    "                                  sum([all_tracks[t][3] for t in tot], []),\n",
    "                                  sum([all_tracks[t][4] for t in tot], []),\n",
    "                                  sum([all_tracks[t][5] for t in tot], []),\n",
    "                                  sum([all_tracks[t][6] for t in tot], [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a3e82ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of tracks and average track length before gap closing: 13225 8.701701323251418\n",
      "\n",
      "Number of tracks and average track length after gap closing: 8529 13.492789307069996\n"
     ]
    }
   ],
   "source": [
    "np.save(track_dir+'all_closed_tracks.npy', np.array(all_closed_tracks, dtype=object))\n",
    "\n",
    "print('\\nNumber of tracks and average track length before gap closing:',\n",
    "      len(all_tracks), np.mean([len(track[0]) for track in all_tracks]))\n",
    "\n",
    "print('\\nNumber of tracks and average track length after gap closing:',\n",
    "      len(all_closed_tracks), np.mean([len(track[0]) for track in all_closed_tracks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70019c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(track_frames)):\n\u001b[0;32m     10\u001b[0m         x, y, z \u001b[38;5;241m=\u001b[39m track_coords[f][\u001b[38;5;241m0\u001b[39m], track_coords[f][\u001b[38;5;241m1\u001b[39m], track_coords[f][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m         tracks\u001b[38;5;241m.\u001b[39mloc[df_index] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_id\u001b[39m\u001b[38;5;124m'\u001b[39m: track_frames[f], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_node_id\u001b[39m\u001b[38;5;124m'\u001b[39m: track_id,\n\u001b[0;32m     12\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_node_id\u001b[39m\u001b[38;5;124m'\u001b[39m: track_nodes[f], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_seg_id\u001b[39m\u001b[38;5;124m'\u001b[39m: track_segs[f], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_frag_id\u001b[39m\u001b[38;5;124m'\u001b[39m: track_frags[f],\n\u001b[0;32m     13\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m: z, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensity\u001b[39m\u001b[38;5;124m'\u001b[39m: track_ints[f], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m: track_widths[f]}\n\u001b[0;32m     14\u001b[0m         df_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m tracks\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_node_id\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1682\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1683\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:2020\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2020\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_maybe_update_cacher(clear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9082\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9079\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9080\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m, other]\n\u001b[1;32m-> 9082\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9086\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9087\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   9088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   9089\u001b[0m     combined_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   9090\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9095\u001b[0m     \u001b[38;5;66;03m# combined_columns.equals check is necessary for preserving dtype\u001b[39;00m\n\u001b[0;32m   9096\u001b[0m     \u001b[38;5;66;03m#  in test_crosstab_normalize\u001b[39;00m\n\u001b[0;32m   9097\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreindex(combined_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:542\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_new_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:612\u001b[0m, in \u001b[0;36m_Concatenator._get_new_axes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    611\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concat_axis \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    615\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:613\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    611\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 613\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    615\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:668\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m idx\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 668\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m \u001b[43m_concat_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _make_concat_multiindex(\n\u001b[0;32m    671\u001b[0m         indexes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    672\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:686\u001b[0m, in \u001b[0;36m_concat_indexes\u001b[1;34m(indexes)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concat_indexes\u001b[39m(indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m--> 686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5120\u001b[0m, in \u001b[0;36mIndex.append\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   5117\u001b[0m names \u001b[38;5;241m=\u001b[39m {obj\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m to_concat}\n\u001b[0;32m   5118\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m-> 5120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5128\u001b[0m, in \u001b[0;36mIndex._concat\u001b[1;34m(self, to_concat, name)\u001b[0m\n\u001b[0;32m   5123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5124\u001b[0m \u001b[38;5;124;03mConcatenate multiple Index objects.\u001b[39;00m\n\u001b[0;32m   5125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5126\u001b[0m to_concat_vals \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[1;32m-> 5128\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5130\u001b[0m is_numeric \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   5131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_backward_compat_public_numeric_index \u001b[38;5;129;01mand\u001b[39;00m is_numeric:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py:151\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    148\u001b[0m             to_concat \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[0;32m    149\u001b[0m             kinds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kinds \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# GH#39817\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBehavior when concatenating bool-dtype and numeric-dtype arrays is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated; in a future version these will cast to object dtype \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Save tracks in the form of one node per row ###\n",
    "tracks = pd.DataFrame(columns={'frame_id', 'unique_node_id', 'frame_node_id', 'frame_seg_id', 'frame_frag_id', 'x', 'y', 'z','intensity','width'})\n",
    "tracks = tracks[['frame_id', 'unique_node_id', 'frame_node_id', 'frame_seg_id', 'frame_frag_id', 'x', 'y', 'z','intensity','width']] # reorder the columns\n",
    "\n",
    "df_index = 0\n",
    "for track_id, track in enumerate(all_closed_tracks):\n",
    "    track_frames, track_nodes, track_segs, track_frags, track_coords, track_ints, track_widths = track[0], track[1], track[2], track[3], track[4], track[5], track[6]\n",
    "\n",
    "    for f in range(len(track_frames)):\n",
    "        x, y, z = track_coords[f][0], track_coords[f][1], track_coords[f][2]\n",
    "        tracks.loc[df_index] = {'frame_id': track_frames[f], 'unique_node_id': track_id,\n",
    "                        'frame_node_id': track_nodes[f], 'frame_seg_id': track_segs[f], 'frame_frag_id': track_frags[f],\n",
    "                        'x': x, 'y': y, 'z': z, 'intensity': track_ints[f], 'width': track_widths[f]}\n",
    "        df_index += 1\n",
    "\n",
    "tracks.sort_values(['unique_node_id'], inplace=True, ignore_index=True)\n",
    "tracks.to_csv(track_dir+'tracks.csv', index=False)\n",
    "### Done saving ###\n",
    "\n",
    "\n",
    "### Save tracks and connected nodes using unique indexing ###\n",
    "new_tracks = pd.DataFrame()\n",
    "for frame in trange(start_frame, end_frame, tracking_interval):\n",
    "\n",
    "    full_graph = full_graph_all_frames[frame]\n",
    "    tracks_frame = tracks[tracks['frame_id'] == frame]\n",
    "\n",
    "    tracked_frame_nodes = tracks_frame['frame_node_id'].astype('int').tolist()\n",
    "    unique_nodes = tracks_frame['unique_node_id'].astype('int').tolist()\n",
    "    frame_to_unique = {tracked_frame_nodes[i]:unique_nodes[i] for i in range(len(tracks_frame))}\n",
    "\n",
    "    def find_connected_unique_nodes(this_node, visited_nodes):\n",
    "\n",
    "        neighs = full_graph.neighbors(this_node)\n",
    "        for visited_node in visited_nodes:\n",
    "            if visited_node in neighs:\n",
    "                neighs.remove(visited_node)\n",
    "\n",
    "        if len(neighs) == 0:\n",
    "            # print ('no neighbor for node',visited_nodes[0])\n",
    "            return\n",
    "\n",
    "        visited_nodes.append(this_node)\n",
    "\n",
    "        for neigh in neighs:\n",
    "            # if the frame node is tracked for this frame, add to list\n",
    "            if neigh in tracked_frame_nodes:\n",
    "                connected_unique_nodes.append(frame_to_unique[neigh])\n",
    "                # print('add',neigh,'for node',visited_nodes[0])\n",
    "            else:\n",
    "                find_connected_unique_nodes(neigh, visited_nodes)\n",
    "        return\n",
    "\n",
    "    all_connected_unique_nodes = []\n",
    "    for node in tracked_frame_nodes:\n",
    "        connected_unique_nodes = []\n",
    "        find_connected_unique_nodes(node, [node])\n",
    "        all_connected_unique_nodes.append(connected_unique_nodes)\n",
    "\n",
    "    tracks_frame.insert(2, 'connected_unique_node_id', [list_to_str(a) for a in all_connected_unique_nodes])\n",
    "    new_tracks = pd.concat([new_tracks, tracks_frame]) # accumulate tracks from each frame\n",
    "\n",
    "# reorder the columns\n",
    "new_tracks = new_tracks[['frame_id', 'unique_node_id', 'frame_node_id', 'frame_seg_id', 'frame_frag_id', 'connected_unique_node_id', 'x', 'y', 'z', 'intensity', 'width']]\n",
    "new_tracks.to_csv(track_dir+'tracks_with_connectivity_unique_index.csv', index=False)\n",
    "\n",
    "### Done saving ###\n",
    "\n",
    "\n",
    "### Save tracks and connected nodes using frame indexing ###\n",
    "new_tracks = pd.DataFrame()\n",
    "for frame in trange(start_frame, end_frame, tracking_interval):\n",
    "\n",
    "    full_graph = full_graph_all_frames[frame]\n",
    "    cc = full_graph.components()\n",
    "\n",
    "    segment_nodes = segment_node_all_frames[frame]\n",
    "    branching_nodes = []\n",
    "    for i in range(len(full_graph.vs)):\n",
    "        if full_graph.vs[i].degree() > 2:\n",
    "            branching_nodes.append(i)\n",
    "    node_to_segment = {}\n",
    "    for segment_id, segment in enumerate(segment_nodes): # segment consists of of segment nodes\n",
    "        for b in segment:\n",
    "            if b in branching_nodes:\n",
    "                node_to_segment[b] = np.nan\n",
    "            else:\n",
    "                node_to_segment[b] = segment_id\n",
    "\n",
    "    coords = full_graph.vs['coordinate']\n",
    "    intensities, widths = full_graph.vs['intensity'], full_graph.vs['width']\n",
    "    tracks_frame = tracks[tracks['frame_id'] == frame]\n",
    "\n",
    "    # add new rows for untracked nodes\n",
    "    untracked = []\n",
    "    tracked_frame_node_id = tracks_frame['frame_node_id'].astype('int').tolist()\n",
    "    for node in range(len(coords)):\n",
    "        if node not in tracked_frame_node_id:\n",
    "            coord = coords[node]\n",
    "            x, y, z = coord[0], coord[1], coord[2]\n",
    "            untracked.append({'frame_id': frame, 'unique_node_id': 'untracked',\n",
    "                              'frame_node_id': node, 'frame_seg_id': node_to_segment[node], 'frame_frag_id': cc.membership[node],\n",
    "                              'x': x, 'y': y, 'z': z,\n",
    "                              'intensity':intensities[node], 'width':widths[node]})\n",
    "\n",
    "    untracked_tracks = pd.DataFrame.from_dict(untracked)\n",
    "    tracks_frame = pd.concat([tracks_frame, untracked_tracks])\n",
    "\n",
    "    # add new column with neighbor nodes for each node\n",
    "    all_connected_frame_nodes = []\n",
    "    tracked_frame_node_id = tracks_frame['frame_node_id'].astype('int').tolist()\n",
    "    for node in tracked_frame_node_id:\n",
    "        neighs = full_graph.neighbors(int(node))\n",
    "        all_connected_frame_nodes.append(neighs)\n",
    "\n",
    "    tracks_frame.insert(2, 'connected_frame_node_id', [list_to_str(a) for a in all_connected_frame_nodes])\n",
    "\n",
    "    # accumulate tracks from each frame\n",
    "    new_tracks = pd.concat([new_tracks, tracks_frame])\n",
    "\n",
    "# reorder the columns\n",
    "new_tracks = new_tracks[['frame_id', 'unique_node_id', 'frame_node_id', 'frame_seg_id', 'frame_frag_id', 'connected_frame_node_id', 'x', 'y', 'z', 'intensity', 'width']]\n",
    "new_tracks.to_csv(track_dir+'tracks_with_connectivity_frame_index.csv', index=False)\n",
    "### Done saving ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
